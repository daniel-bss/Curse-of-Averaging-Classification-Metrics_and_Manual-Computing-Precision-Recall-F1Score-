{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4823c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c29e4",
   "metadata": {},
   "source": [
    "### 1. BALANCED ACTUAL AND PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bbce36a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36111111, 0.25      , 0.38709677, 0.23529412, 0.10185185,\n",
       "       0.4400978 , 0.14951677, 0.27946508, 0.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1433600, 9)\n",
      "\n",
      "Time execution: 4.443114995956421\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "bankloan = pd.read_csv('bankloan.csv')\n",
    "features = MinMaxScaler().fit_transform(bankloan.values[:,:8])\n",
    "target = bankloan.values[:,8].reshape(-1,1)\n",
    "values = np.concatenate([features, target], axis = 1)\n",
    "\n",
    "for i in range(11):\n",
    "    values = np.append(values, values, axis = 0)\n",
    "np.random.shuffle(values)\n",
    "np.random.shuffle(values)\n",
    "display(values[0])\n",
    "print('Shape:', values.shape)\n",
    "\n",
    "print('\\nTime execution:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5132b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the values into X and y \n",
    "X = values[:,:8] \n",
    "y = values[:,8].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34954437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1433600,)\n"
     ]
    }
   ],
   "source": [
    "# Here is the 0s and 1s from y:\n",
    "\n",
    "display(y[:10])\n",
    "print('Shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d533967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int16), array([1058816,  374784], dtype=int64))\n",
      "Weight of 1s: 0.26142857142857145\n"
     ]
    }
   ],
   "source": [
    "# Taking a glance of y info:\n",
    "\n",
    "print(np.unique(y, return_counts=True))\n",
    "print('Weight of 1s:', 374784/(1058816 + 374784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5cb76efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1433600,)\n",
      "5\n",
      "\n",
      "Time execution: 34.272103786468506\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time() # measuring time of execution\n",
    "\n",
    "list_test_index = []\n",
    "result_kfold = []\n",
    "actual = []\n",
    "for train_index, test_index in KFold(n_splits=5).split(y):\n",
    "    logreg = LogisticRegression()\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    # y_test = not needed. we are not doing any performance test. instead, only need y_pred later from model.predict(X_test)\n",
    "    \n",
    "    logreg.fit(X_train, y_train)\n",
    "    result_kfold += list(logreg.predict(X_test))\n",
    "    list_test_index.append(test_index)\n",
    "    \n",
    "result_kfold = np.array(result_kfold) # transforming list() into NumPy array, we need it for indexing\n",
    "print(result_kfold.shape) # must be the same as shape of y, since  we are predicting all the 5 folds\n",
    "print(len(list_test_index)) # must be 5, which is filled by 5 groups of indexing values\n",
    "\n",
    "print('\\nTime execution:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56e2f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1]\n",
      "[211702  75018]\n",
      "[211769  74951]\n",
      "[211937  74783]\n",
      "[211522  75198]\n",
      "[211886  74834]\n"
     ]
    }
   ],
   "source": [
    "# ACTUAL\n",
    "print('Labels:', np.unique(y))\n",
    "for i in list_test_index:\n",
    "    print(np.unique(y[i], return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11cb7923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1]\n",
      "[230439  56281]\n",
      "[230621  56099]\n",
      "[230699  56021]\n",
      "[230131  56589]\n",
      "[230299  56421]\n",
      "\n",
      "Time execution: 31.87156343460083\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION BY THE BUILT IN SKLEARN CROSS VALIDATION (cross_val_predic())\n",
    "\n",
    "t0 = time.time() # measuring time of execution\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "result = cross_val_predict(logreg, X, y, cv = 5) # cv is the same as n_splits = 5 \n",
    "\n",
    "print('Labels:', np.unique(result))\n",
    "for i in list_test_index:\n",
    "    print(np.unique(result[i], return_counts=True)[1])\n",
    "    \n",
    "print('\\nTime execution:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cbb7c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1]\n",
      "[230439  56281]\n",
      "[230621  56099]\n",
      "[230284  56436]\n",
      "[230548  56172]\n",
      "[230299  56421]\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION WITH SEQUENTIAL INDEX (by the built-in sklearn KFold())\n",
    "\n",
    "print('Labels:', np.unique(result_kfold))\n",
    "for i in list_test_index:\n",
    "    print(np.unique(np.array(result_kfold)[i], return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92978aac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 \n",
      "\n",
      "  TP: 38240\n",
      "  FN: 36778\n",
      "  FP: 18041\n",
      "  TN: 193661\n",
      "\n",
      "  Precision: 0.679447771006201\n",
      "  Recall: 0.50974432802794\n",
      "  F1-Score: 0.5824872999794363\n",
      " *Sensitivity: 0.679447771006201\n",
      " *Specificity: 0.9147811546419023\n",
      "====================================================================================================\n",
      "Fold 2 \n",
      "\n",
      "  TP: 37870\n",
      "  FN: 37081\n",
      "  FP: 18229\n",
      "  TN: 193540\n",
      "\n",
      "  Precision: 0.675056596374267\n",
      "  Recall: 0.5052634387800029\n",
      "  F1-Score: 0.5779473483403281\n",
      " *Sensitivity: 0.675056596374267\n",
      " *Specificity: 0.9139203566149908\n",
      "====================================================================================================\n",
      "Fold 3 \n",
      "\n",
      "  TP: 37978\n",
      "  FN: 36805\n",
      "  FP: 18458\n",
      "  TN: 193479\n",
      "\n",
      "  Precision: 0.6729392586292438\n",
      "  Recall: 0.5078426915208002\n",
      "  F1-Score: 0.5788490995968573\n",
      " *Sensitivity: 0.6729392586292438\n",
      " *Specificity: 0.9129080811750662\n",
      "====================================================================================================\n",
      "Fold 4 \n",
      "\n",
      "  TP: 38238\n",
      "  FN: 36960\n",
      "  FP: 17934\n",
      "  TN: 193588\n",
      "\n",
      "  Precision: 0.6807306131168553\n",
      "  Recall: 0.508497566424639\n",
      "  F1-Score: 0.5821420415620004\n",
      " *Sensitivity: 0.6807306131168553\n",
      " *Specificity: 0.915214493055096\n",
      "====================================================================================================\n",
      "Fold 5 \n",
      "\n",
      "  TP: 38138\n",
      "  FN: 36696\n",
      "  FP: 18283\n",
      "  TN: 193603\n",
      "\n",
      "  Precision: 0.6759539887630492\n",
      "  Recall: 0.5096346580431355\n",
      "  F1-Score: 0.5811283379680774\n",
      " *Sensitivity: 0.6759539887630492\n",
      " *Specificity: 0.9137130343675373\n",
      "====================================================================================================\n",
      "\n",
      "Time execution: 6.174618244171143\n"
     ]
    }
   ],
   "source": [
    "# CALCULATING TP, FN, FP, RECALL, PRECISION, F1-SCORE\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "list_precision, list_recall, list_f1score = [], [], []\n",
    "sum_tp, sum_fn, sum_fp = 0, 0, 0\n",
    "TP, FN, FP, TN = [], [], [], []\n",
    "\n",
    "for count,i in enumerate(list_test_index):\n",
    "    print('Fold',count+1,'\\n')\n",
    "    tp, fn, fp, tn  = 0, 0, 0, 0\n",
    "    for a,b in zip(y[i], result_kfold[i]): # (actual, prediction)\n",
    "        if a == b:\n",
    "            if (a == 1) and (b == 1):\n",
    "                tp += 1\n",
    "            elif (a == 0) and (b == 0):\n",
    "                tn += 1\n",
    "        elif a != b:\n",
    "            if (a == 1) and (b == 0):\n",
    "                fn += 1\n",
    "            elif (a == 0) and (b == 1):\n",
    "                fp += 1\n",
    "    sum_tp += tp\n",
    "    sum_fn += fn\n",
    "    sum_fp += fp\n",
    "    \n",
    "    TP.append(tp); FN.append(fn); FP.append(fp); TN.append(tn)\n",
    "     \n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    f1_score = 2 / (1/precision + 1/recall)\n",
    "    specificity = tn/(tn+fp)\n",
    "\n",
    "\n",
    "    list_precision.append(precision); list_recall.append(recall); list_f1score.append(f1_score)\n",
    "        \n",
    "    print('  TP:', tp)\n",
    "    print('  FN:', fn)\n",
    "    print('  FP:', fp)\n",
    "    print('  TN:', tn)\n",
    "    print()\n",
    "    print('  Precision:', precision)\n",
    "    print('  Recall:', recall)\n",
    "    print('  F1-Score:', f1_score)\n",
    "    # *optional addition, since they don't appear in Confusion Matrix (used for plotting ROC curve instead)\n",
    "    print(' *Sensitivity:', precision)  # sensitivity and precision are the same\n",
    "    print(' *Specificity:', specificity) \n",
    "    print('='*100)\n",
    "    \n",
    "print('\\nTime execution:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30c4896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6768256455779232\n",
      "Recall: 0.5081965365593035\n",
      "F1-Score: 0.58051082548934\n"
     ]
    }
   ],
   "source": [
    "# RECALL, PRECISION, F1-SCORE IF BEING AVERAGED DIRECTLY (np.sum(list))\n",
    "\n",
    "print('Precision:', np.mean(list_precision))\n",
    "print('Recall:', np.mean(list_recall))\n",
    "print('F1-Score:', np.mean(list_f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22a9247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.676822702898628\n",
      "Recall: 0.5081967213114754\n",
      "F1-Score: 0.5805121359112334\n"
     ]
    }
   ],
   "source": [
    "# RECALL, PRECISION, F1-SCORE IF NOT BEING AVERAGED DIRECTLY\n",
    "# example: Precision = sum_tp / (sum_tp + sum_fp)\n",
    "# so the overall result of each Fold, will be summed first\n",
    "\n",
    "precision_ = sum_tp/(sum_tp + sum_fp)\n",
    "recall_ = sum_tp/(sum_tp + sum_fn)\n",
    "\n",
    "print('Precision:', precision_)\n",
    "print('Recall:', recall_)\n",
    "print('F1-Score:', 2 / (1/precision_ + 1/recall_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ee161",
   "metadata": {},
   "source": [
    "# CONCLUSION:\n",
    "As we can see before when separating the values of the Actual and Predicted 1s, they don't differ that much, <br>just around 133 - 146 (yes i had their standard deviation) out of 50000 - 70000 of 1s in each fold<br>\n",
    "Hence, by directly averaging their metrics (Precision, Recall, F1-Score) almost precisely* the same as summing their properties first and do the math. <br>\n",
    "*(Precisely the same, because their results are the same for the first 5-6 digits) \n",
    "\n",
    "What about on the imbalance 0s and 1s? We're about to figure out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d622a",
   "metadata": {},
   "source": [
    "### 2. IMBALANCED ACTUAL AND PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5c22be3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41666667, 0.25      , 0.4516129 , 0.08823529, 0.15740741,\n",
       "       0.00977995, 0.02222368, 0.00526278, 0.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1433600, 9)\n",
      "\n",
      "Time execution: 4.440523862838745\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "bankloan = pd.read_csv('bankloan.csv')\n",
    "features = MinMaxScaler().fit_transform(bankloan.values[:,:8])\n",
    "target = bankloan.values[:,8].reshape(-1,1)\n",
    "values = np.concatenate([features, target], axis = 1)\n",
    "\n",
    "for i in range(11):\n",
    "    values = np.append(values, values, axis = 0)\n",
    "np.random.shuffle(values)\n",
    "np.random.shuffle(values)\n",
    "display(values[0])\n",
    "print('Shape:', values.shape)\n",
    "\n",
    "print('\\nTime execution:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0b1f96af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# sort the last column for 0 to 1\n",
    "values = values[values[:, 8].argsort()]\n",
    "print(values[:5, -1]) # first 5 rows\n",
    "print(values[-5:, -1]) # last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "90b59c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the values into X and y \n",
    "X = values[:,:8] \n",
    "y = values[:,8].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0b581fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1433600,)\n"
     ]
    }
   ],
   "source": [
    "# Here is the 0s and 1s from y:\n",
    "\n",
    "display(y[:10])\n",
    "print('Shape:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "44587a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int16), array([1058816,  374784], dtype=int64))\n",
      "Weight of 1s: 0.26142857142857145\n"
     ]
    }
   ],
   "source": [
    "# Taking a glance of y info:\n",
    "\n",
    "print(np.unique(y, return_counts=True))\n",
    "print('Weight of 1s:', 374784/(1058816 + 374784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a713ad75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1433600,)\n",
      "5\n",
      "\n",
      "Time execution: 32.54437518119812\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time() # measuring time of execution\n",
    "\n",
    "list_test_index = []\n",
    "result_kfold = []\n",
    "actual = []\n",
    "for train_index, test_index in KFold(n_splits=5).split(y):\n",
    "    logreg = LogisticRegression()\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    # y_test = not needed. we are not doing any performance test. instead, only need y_pred later from model.predict(X_test)\n",
    "    \n",
    "    logreg.fit(X_train, y_train)\n",
    "    result_kfold += list(logreg.predict(X_test))\n",
    "    list_test_index.append(test_index)\n",
    "    \n",
    "result_kfold = np.array(result_kfold) # transforming list() into NumPy array, we need it for indexing\n",
    "print(result_kfold.shape) # must be the same as shape of y, since  we are predicting all the 5 folds\n",
    "print(len(list_test_index)) # must be 5, which is filled by 5 groups of indexing values\n",
    "\n",
    "print('\\nTime execution:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "439cbf95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1]\n",
      "[286720]\n",
      "[286720]\n",
      "[286720]\n",
      "[198656  88064]\n",
      "[286720]\n"
     ]
    }
   ],
   "source": [
    "# ACTUAL\n",
    "# NOTE: The result is significantly weird, since all of the 1s are on the last rows\n",
    "# So just ignore the 'Labels:', and let it be known that the 1st - 3rd rows are all 0s, then the 5th rows is all 1s\n",
    "\n",
    "print('Labels:', np.unique(y))\n",
    "for i in list_test_index:\n",
    "    print(np.unique(y[i], return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c7211752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1]\n",
      "[261677  25043]\n",
      "[261638  25082]\n",
      "[262235  24485]\n",
      "[224643  62077]\n",
      "[141192 145528]\n",
      "\n",
      "Time execution: 36.78186011314392\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION BY THE BUILT IN SKLEARN CROSS VALIDATION (cross_val_predic())\n",
    "\n",
    "t0 = time.time() # measuring time of execution\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "result = cross_val_predict(logreg, X, y, cv = 5) # cv is the same as n_splits = 5 \n",
    "\n",
    "print('Labels:', np.unique(result))\n",
    "for i in list_test_index:\n",
    "    print(np.unique(result[i], return_counts=True)[1])\n",
    "    \n",
    "print('\\nTime execution:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "92a585f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1]\n",
      "[255514  31206]\n",
      "[255487  31233]\n",
      "[255833  30887]\n",
      "[228861  57859]\n",
      "[243061  43659]\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION WITH SEQUENTIAL INDEX (by the built-in sklearn KFold())\n",
    "\n",
    "print('Labels:', np.unique(result_kfold))\n",
    "for i in list_test_index:\n",
    "    print(np.unique(np.array(result_kfold)[i], return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac5feb4",
   "metadata": {},
   "source": [
    "#### Note: The prediction value counts  above are neat again. And can it be seen that the 1s are not uniform anymore. IMBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e3ce808d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 \n",
      "\n",
      "  TP: 0.01\n",
      "  FN: 0.01\n",
      "  FP: 31206.010000000002\n",
      "  TN: 255514.01\n",
      "\n",
      "  Precision: 3.2045098990515294e-07\n",
      "  Recall: 0.5\n",
      "  F1-Score: 6.409015690552213e-07\n",
      " *Sensitivity: 3.2045098990515294e-07\n",
      " *Specificity: 0.8911620820896985\n",
      "====================================================================================================\n",
      "Fold 2 \n",
      "\n",
      "  TP: 0.01\n",
      "  FN: 0.01\n",
      "  FP: 31233.010000000002\n",
      "  TN: 255487.01\n",
      "\n",
      "  Precision: 3.201739697281915e-07\n",
      "  Recall: 0.5\n",
      "  F1-Score: 6.40347529411162e-07\n",
      " *Sensitivity: 3.201739697281915e-07\n",
      " *Specificity: 0.8910679135694815\n",
      "====================================================================================================\n",
      "Fold 3 \n",
      "\n",
      "  TP: 0.01\n",
      "  FN: 0.01\n",
      "  FP: 30887.010000000002\n",
      "  TN: 255833.01\n",
      "\n",
      "  Precision: 3.237605958749015e-07\n",
      "  Recall: 0.5\n",
      "  F1-Score: 6.475207724663807e-07\n",
      " *Sensitivity: 3.237605958749015e-07\n",
      " *Specificity: 0.892274665717448\n",
      "====================================================================================================\n",
      "Fold 4 \n",
      "\n",
      "  TP: 43024.01\n",
      "  FN: 45040.01\n",
      "  FP: 14835.01\n",
      "  TN: 183821.01\n",
      "\n",
      "  Precision: 0.7436007384846822\n",
      "  Recall: 0.48855378166929014\n",
      "  F1-Score: 0.5896808345001584\n",
      " *Sensitivity: 0.7436007384846822\n",
      " *Specificity: 0.9253231288938538\n",
      "====================================================================================================\n",
      "Fold 5 \n",
      "\n",
      "  TP: 43659.01\n",
      "  FN: 243061.01\n",
      "  FP: 0.01\n",
      "  TN: 0.01\n",
      "\n",
      "  Precision: 0.9999997709522568\n",
      "  Recall: 0.15227053206818275\n",
      "  F1-Score: 0.2642964880580802\n",
      " *Sensitivity: 0.9999997709522568\n",
      " *Specificity: 0.5\n",
      "====================================================================================================\n",
      "\n",
      "Time execution: 6.840925931930542\n"
     ]
    }
   ],
   "source": [
    "# CALCULATING TP, FN, FP, RECALL, PRECISION, F1-SCORE\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "list_precision, list_recall, list_f1score = [], [], []\n",
    "sum_tp, sum_fn, sum_fp = 0, 0, 0\n",
    "TP, FN, FP, TN = [], [], [], []\n",
    "\n",
    "for count,i in enumerate(list_test_index):\n",
    "    print('Fold',count+1,'\\n')\n",
    "    tp, fn, fp, tn  = 0.01, 0.01, 0.01, 0.01 # initialized by 0.01 to prevent division by zero. since our goal is just to see the effect of averaging metrics properties\n",
    "    for a,b in zip(y[i], result_kfold[i]): # (actual, prediction)\n",
    "        if a == b:\n",
    "            if (a == 1) and (b == 1):\n",
    "                tp += 1\n",
    "            elif (a == 0) and (b == 0):\n",
    "                tn += 1\n",
    "        elif a != b:\n",
    "            if (a == 1) and (b == 0):\n",
    "                fn += 1\n",
    "            elif (a == 0) and (b == 1):\n",
    "                fp += 1\n",
    "    sum_tp += tp\n",
    "    sum_fn += fn\n",
    "    sum_fp += fp\n",
    "    \n",
    "    TP.append(tp); FN.append(fn); FP.append(fp); TN.append(tn)\n",
    "     \n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    f1_score = 2 / (1/precision + 1/recall)\n",
    "    specificity = tn/(tn+fp)\n",
    "\n",
    "\n",
    "    list_precision.append(precision); list_recall.append(recall); list_f1score.append(f1_score)\n",
    "        \n",
    "    print('  TP:', tp)\n",
    "    print('  FN:', fn)\n",
    "    print('  FP:', fp)\n",
    "    print('  TN:', tn)\n",
    "    print()\n",
    "    print('  Precision:', precision)\n",
    "    print('  Recall:', recall)\n",
    "    print('  F1-Score:', f1_score)\n",
    "    # *optional addition, since they don't appear in Confusion Matrix (used for plotting ROC curve instead)\n",
    "    print(' *Sensitivity:', precision)  # sensitivity and precision are the same\n",
    "    print(' *Specificity:', specificity) \n",
    "    print('='*100)\n",
    "    \n",
    "print('\\nTime execution:', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6fd38d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3487202947644989\n",
      "Recall: 0.42816486274749455\n",
      "F1-Score: 0.17079585026562188\n"
     ]
    }
   ],
   "source": [
    "# RECALL, PRECISION, F1-SCORE IF BEING AVERAGED DIRECTLY (np.sum(list))\n",
    "\n",
    "print('Precision:', np.mean(list_precision))\n",
    "print('Recall:', np.mean(list_recall))\n",
    "print('F1-Score:', np.mean(list_f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cac65296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4448841407053127\n",
      "Recall: 0.23128796018827907\n",
      "F1-Score: 0.30434957398527673\n"
     ]
    }
   ],
   "source": [
    "# RECALL, PRECISION, F1-SCORE IF NOT BEING AVERAGED DIRECTLY\n",
    "# example: Precision = sum_tp / (sum_tp + sum_fp)\n",
    "# so the overall result of each Fold, will be summed first\n",
    "\n",
    "precision_ = sum_tp/(sum_tp + sum_fp)\n",
    "recall_ = sum_tp/(sum_tp + sum_fn)\n",
    "\n",
    "print('Precision:', precision_)\n",
    "print('Recall:', recall_)\n",
    "print('F1-Score:', 2 / (1/precision_ + 1/recall_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90293b95",
   "metadata": {},
   "source": [
    "# FINAL CONCLUSION\n",
    "Now it's been proven that averaging metrics is not trivial. So do not take the mean of cross validation scores unless you check that the amount of Actual 1s and Prediction 1s are correspondingly uniform. Or the easiest way is just by looking at the standard deviation of the scores. If it's low, it's okay to take the average of it. Else, go sum each of its TP, FP, FN in order to find the true average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
